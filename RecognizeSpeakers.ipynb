{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting mp4 to wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 217 mp4 files\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\100\\Convers_100.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\100\\Convers_100.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\100\\Inten_100.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\100\\Inten_100.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\100\\Spon_100.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\100\\Spon_100.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\101\\Convers_101.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\101\\Convers_101.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\101\\Inten_101.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\101\\Inten_101.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\101\\Spon_101.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\101\\Spon_101.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\102\\Convers_102.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\102\\Convers_102.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\102\\Inten_102.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\102\\Inten_102.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\102\\Spon_102.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\102\\Spon_102.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\103\\Convers_103.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\103\\Convers_103.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\103\\Inten_103.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\103\\Inten_103.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\103\\Spon_103.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\103\\Spon_103.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\104\\Convers_104.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\104\\Convers_104.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\104\\Inten_104.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\104\\Inten_104.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\104\\Spon_104.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\104\\Spon_104.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\106\\Convers_106.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\106\\Convers_106.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\107\\Convers_107.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\107\\Convers_107.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\107\\Inten_107.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\107\\Inten_107.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\107\\Spon_107.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\107\\Spon_107.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\109\\Convers_109.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\109\\Convers_109.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\109\\inten_109.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\109\\inten_109.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\109\\Spon_109.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\109\\Spon_109.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\11\\Convers_11.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\11\\Convers_11.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\11\\Spon_11.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\11\\Spon_11.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\110\\Convers_110.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\110\\Convers_110.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\110\\Inten_110.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\110\\Inten_110.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\110\\Spon_110.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\110\\Spon_110.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\111\\Convers_111.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\111\\Convers_111.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\111\\Inten_111.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\111\\Inten_111.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\111\\Spon_111.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\111\\Spon_111.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\112\\112_conversation.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\112\\112_conversation.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\112\\112_freeplay.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\112\\112_freeplay.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\113\\Convers_113.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\113\\Convers_113.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\113\\Inten_113.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\113\\Inten_113.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\113\\SponPlay_113.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\113\\SponPlay_113.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\114\\Convers_114.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\114\\Convers_114.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\114\\Inten_114.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\114\\Inten_114.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\114\\Spon_114.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\114\\Spon_114.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\115\\Conver_115.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\115\\Conver_115.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\115\\Inten_115.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\115\\Inten_115.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\115\\Spon_115.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\115\\Spon_115.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\116\\Convers_116.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\116\\Convers_116.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\116\\Inten_116.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\116\\Inten_116.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\116\\Spon_116.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\116\\Spon_116.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\117\\Convers_117.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\117\\Convers_117.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\117\\Inten_117.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\117\\Inten_117.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\117\\Spon_117.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\117\\Spon_117.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\120\\Convers_120.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\120\\Convers_120.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\120\\Inten_120.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\120\\Inten_120.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\120\\Spon_120.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\120\\Spon_120.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\121\\Convers_121.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\121\\Convers_121.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\121\\Inten_121.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\121\\Inten_121.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\121\\Spon_121.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\121\\Spon_121.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\122\\Convers_122.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\122\\Convers_122.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\122\\Inten_122.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\122\\Inten_122.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\122\\Spon_122.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\122\\Spon_122.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\123\\Convers_123.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\123\\Convers_123.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\123\\Inten_123.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\123\\Inten_123.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\123\\Spon_123.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\123\\Spon_123.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\124\\Convers_124.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\124\\Convers_124.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\124\\Inten_124.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\124\\Inten_124.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\124\\Spon_124.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\124\\Spon_124.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\125\\Convers_125.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\125\\Convers_125.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\125\\Inten_125.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\125\\Inten_125.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\125\\Spon_125.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\125\\Spon_125.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\126\\Conver_126.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\126\\Conver_126.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\126\\Inten_126.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\126\\Inten_126.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\126\\Spon_126.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\126\\Spon_126.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\127\\Convers_127.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\127\\Convers_127.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\127\\Inten_127.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\127\\Inten_127.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\127\\SponPartOne_127.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\127\\SponPartOne_127.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\127\\SponPartThree_127.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\127\\SponPartThree_127.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\127\\SponPartTwo_127.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\127\\SponPartTwo_127.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\128\\convers_128.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\128\\convers_128.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\128\\Inten_128.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\128\\Inten_128.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\128\\Spon_128.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\128\\Spon_128.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\13\\13_conversation.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\13\\13_conversation.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\13\\13_intenplay.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\13\\13_intenplay.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\13\\13_sponplay.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\13\\13_sponplay.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\200\\200_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\200\\200_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\200\\200_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\200\\200_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\200\\200_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\200\\200_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\201\\201_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\201\\201_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\201\\201_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\201\\201_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\201\\201_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\201\\201_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\203\\203.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\203\\203.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\205\\205_conver.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\205\\205_conver.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\205\\205_intent.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\205\\205_intent.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\205\\205_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\205\\205_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\206\\206_conver.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\206\\206_conver.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\206\\206_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\206\\206_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\206\\206_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\206\\206_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\209\\209_conv.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\209\\209_conv.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\209\\209_intentional.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\209\\209_intentional.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\209\\209_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\209\\209_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\210\\210_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\210\\210_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\210\\210_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\210\\210_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\210\\210_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\210\\210_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\211\\211_covers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\211\\211_covers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\211\\211_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\211\\211_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\211\\211_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\211\\211_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\212\\212_conver.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\212\\212_conver.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\212\\212_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\212\\212_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\212\\212_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\212\\212_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\213\\213_conver.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\213\\213_conver.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\213\\213_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\213\\213_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\213\\213_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\213\\213_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\214\\214_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\214\\214_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\214\\214_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\214\\214_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\214\\214_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\214\\214_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\215\\215_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\215\\215_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\215\\215_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\215\\215_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\215\\215_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\215\\215_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\217\\217_conver.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\217\\217_conver.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\217\\217_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\217\\217_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\217\\217_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\217\\217_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\218\\218_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\218\\218_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\218\\218_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\218\\218_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\218\\218_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\218\\218_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\219\\219_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\219\\219_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\219\\219_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\219\\219_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\219\\spon_219.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\219\\spon_219.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\220\\220_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\220\\220_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\220\\220_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\220\\220_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\221\\221_conv.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\221\\221_conv.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\221\\221_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\221\\221_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\221\\221_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\221\\221_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\222\\222_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\222\\222_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\222\\222_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\222\\222_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\222\\222_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\222\\222_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\224\\224_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\224\\224_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\224\\224_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\224\\224_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\224\\224_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\224\\224_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\225\\225_conver.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\225\\225_conver.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\225\\225_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\225\\225_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\225\\225_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\225\\225_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\228\\228_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\228\\228_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\228\\228_intetn.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\228\\228_intetn.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\228\\228_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\228\\228_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\230\\230_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\230\\230_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\230\\230_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\230\\230_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\230\\230_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\230\\230_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\231\\231_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\231\\231_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\231\\231_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\231\\231_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\231\\231_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\231\\231_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\232\\232_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\232\\232_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\232\\232_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\232\\232_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\232\\232_sponOne.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\232\\232_sponOne.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\232\\232_sponTwo.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\232\\232_sponTwo.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\234\\234_conv.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\234\\234_conv.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\234\\234_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\234\\234_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\234\\234_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\234\\234_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\237\\237_conv.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\237\\237_conv.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\237\\237_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\237\\237_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\237\\237_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\237\\237_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\238\\238_Conv.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\238\\238_Conv.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\238\\238_Inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\238\\238_Inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\238\\238_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\238\\238_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\239\\239_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\239\\239_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\239\\239_intent.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\239\\239_intent.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\239\\239_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\239\\239_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\24\\24_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\24\\24_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\240\\240_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\240\\240_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\240\\240_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\240\\240_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\240\\240_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\240\\240_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\241\\241_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\241\\241_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\241\\241_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\241\\241_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\241\\241_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\241\\241_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\242\\242_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\242\\242_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\242\\242_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\242\\242_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\242\\242_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\242\\242_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\244\\244_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\244\\244_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\244\\244_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\244\\244_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\244\\244_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\244\\244_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\245\\245_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\245\\245_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\245\\245_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\245\\245_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\245\\245_sponOne.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\245\\245_sponOne.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\245\\245_sponTwo.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\245\\245_sponTwo.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\248\\248_Conv.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\248\\248_Conv.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\248\\248_Inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\248\\248_Inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\248\\248_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\248\\248_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\250\\250_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\250\\250_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\250\\250_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\250\\250_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\250\\250_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\250\\250_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\251\\251_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\251\\251_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\251\\251_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\251\\251_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\251\\251_Spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\251\\251_Spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\252\\252_conv.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\252\\252_conv.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\252\\252_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\252\\252_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\252\\252_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\252\\252_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\253\\253_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\253\\253_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\253\\253_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\253\\253_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\253\\253_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\253\\253_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\255\\255_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\255\\255_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\255\\255_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\255\\255_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\255\\255_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\255\\255_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\258\\258_conv.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\258\\258_conv.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\258\\258_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\258\\258_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\258\\258_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\258\\258_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\260\\260_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\260\\260_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\260\\260_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\260\\260_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\260\\260_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\260\\260_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\27\\27_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\27\\27_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\27\\27_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\27\\27_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\27\\27_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\27\\27_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\29\\29_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\29\\29_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\29\\29_inten.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\29\\29_inten.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\29\\29_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\29\\29_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\3\\Spon_3.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\3\\Spon_3.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\30\\30_convers.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\30\\30_convers.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\30\\30_spon.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\30\\30_spon.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\5\\5_intenplay.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\5\\5_intenplay.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\5\\5_spontplay.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\5\\5_spontplay.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\6\\Convers_6.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\6\\Convers_6.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\6\\intent_6.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\6\\intent_6.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\6\\spon_6.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\6\\spon_6.wav\n",
      "OK: O:\\MyThesis\\DataSets\\Michal\\Video\\7\\Conves_7.mp4 -> O:\\MyThesis\\DataSets\\Michal\\Audio\\7\\Conves_7.wav\n",
      "Conversion finished.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import subprocess\n",
    "\n",
    "# def convert_m4a_to_wav(input_folder, output_folder=None, sample_rate=16000):\n",
    "#     \"\"\"\n",
    "#     Convert all .m4a files in input_folder to .wav using ffmpeg.\n",
    "    \n",
    "#     Args:\n",
    "#         input_folder (str): Path containing .m4a files.\n",
    "#         output_folder (str): Destination folder for .wav files (defaults to input folder).\n",
    "#         sample_rate (int): Desired sample rate for output wav files (default 16000 Hz).\n",
    "#     \"\"\"\n",
    "#     if output_folder is None:\n",
    "#         output_folder = input_folder\n",
    "\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "\n",
    "#     for file_name in os.listdir(input_folder):\n",
    "#         if file_name.lower().endswith(\".m4a\"):\n",
    "#             input_path = os.path.join(input_folder, file_name)\n",
    "#             output_name = os.path.splitext(file_name)[0] + \".wav\"\n",
    "#             output_path = os.path.join(output_folder, output_name)\n",
    "\n",
    "#             command = [\n",
    "#                 \"ffmpeg\",\n",
    "#                 \"-y\",                 # overwrite without asking\n",
    "#                 \"-i\", input_path,     # input file\n",
    "#                 \"-ar\", str(sample_rate),  # resample\n",
    "#                 output_path\n",
    "#             ]\n",
    "\n",
    "#             print(f\"Converting: {input_path} -> {output_path}\")\n",
    "#             subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     convert_m4a_to_wav(r\"O:\\\\MyThesis\\\\DataSets\\\\Michal\\\\Video\\\\\",\n",
    "#                        r\"O:\\\\MyThesis\\\\DataSets\\\\Michal\\\\Audio\")\n",
    "\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# -------------------------------------------------\n",
    "INPUT_ROOT  = r\"O:\\\\MyThesis\\\\DataSets\\\\Michal\\\\Video\\\\\"   # folder with mp4 files\n",
    "OUTPUT_ROOT = r\"O:\\\\MyThesis\\\\DataSets\\\\Michal\\\\Audio\\\\\"     # where wav files will be saved\n",
    "\n",
    "SAMPLE_RATE = 16000   # Hz (good for speech / ML)\n",
    "CHANNELS    = 1       # 1 = mono, 2 = stereo\n",
    "OVERWRITE   = False   # True = overwrite existing wav files\n",
    "# -------------------------------------------------\n",
    "\n",
    "\n",
    "def check_ffmpeg():\n",
    "    \"\"\"Check that ffmpeg is installed and available.\"\"\"\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [\"ffmpeg\", \"-version\"],\n",
    "            stdout=subprocess.DEVNULL,\n",
    "            stderr=subprocess.DEVNULL,\n",
    "            check=True\n",
    "        )\n",
    "    except Exception:\n",
    "        raise RuntimeError(\n",
    "            \"FFmpeg is not installed or not in PATH.\\n\"\n",
    "            \"Install FFmpeg and restart the terminal / VS Code.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def convert_tree_mp4_to_wav(input_root, output_root):\n",
    "    input_root = Path(input_root).resolve()\n",
    "    output_root = Path(output_root).resolve()\n",
    "\n",
    "    mp4_files = list(input_root.rglob(\"*.mp4\"))\n",
    "\n",
    "    print(f\"Found {len(mp4_files)} mp4 files\")\n",
    "\n",
    "    for mp4_path in mp4_files:\n",
    "        # Keep folder structure\n",
    "        relative_path = mp4_path.relative_to(input_root)\n",
    "\n",
    "        # Change extension to .wav\n",
    "        wav_path = output_root / relative_path.with_suffix(\".wav\")\n",
    "\n",
    "        # Create output folders if needed\n",
    "        wav_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if wav_path.exists() and not OVERWRITE:\n",
    "            print(f\"SKIP: {wav_path}\")\n",
    "            continue\n",
    "\n",
    "        cmd = [\n",
    "            \"ffmpeg\",\n",
    "            \"-y\" if OVERWRITE else \"-n\",\n",
    "            \"-i\", str(mp4_path),\n",
    "            \"-vn\",                       # no video\n",
    "            \"-ac\", str(CHANNELS),\n",
    "            \"-ar\", str(SAMPLE_RATE),\n",
    "            \"-c:a\", \"pcm_s16le\",         # WAV PCM 16-bit\n",
    "            str(wav_path)\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            subprocess.run(cmd, check=True)\n",
    "            print(f\"OK: {mp4_path} -> {wav_path}\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"ERROR converting: {mp4_path}\")\n",
    "\n",
    "    print(\"Conversion finished.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_ffmpeg()\n",
    "    convert_tree_mp4_to_wav(INPUT_ROOT, OUTPUT_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading wav file and creating csv file results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] Convers_100.wav -> Convers_100_diarization.csv | segs=59 | speakers=2\n",
      "[ok] Inten_100.wav -> Inten_100_diarization.csv | segs=60 | speakers=2\n",
      "[ok] Spon_100.wav -> Spon_100_diarization.csv | segs=57 | speakers=2\n",
      "[ok] Convers_101.wav -> Convers_101_diarization.csv | segs=163 | speakers=2\n",
      "[ok] Inten_101.wav -> Inten_101_diarization.csv | segs=328 | speakers=2\n",
      "[ok] Spon_101.wav -> Spon_101_diarization.csv | segs=304 | speakers=2\n",
      "[ok] Convers_102.wav -> Convers_102_diarization.csv | segs=165 | speakers=2\n",
      "[ok] Inten_102.wav -> Inten_102_diarization.csv | segs=64 | speakers=2\n",
      "[ok] Spon_102.wav -> Spon_102_diarization.csv | segs=61 | speakers=2\n",
      "[ok] Convers_103.wav -> Convers_103_diarization.csv | segs=133 | speakers=2\n",
      "[ok] Inten_103.wav -> Inten_103_diarization.csv | segs=286 | speakers=2\n",
      "[ok] Spon_103.wav -> Spon_103_diarization.csv | segs=338 | speakers=2\n",
      "[ok] Convers_104.wav -> Convers_104_diarization.csv | segs=55 | speakers=2\n",
      "[ok] Inten_104.wav -> Inten_104_diarization.csv | segs=40 | speakers=2\n",
      "[ok] Spon_104.wav -> Spon_104_diarization.csv | segs=45 | speakers=2\n",
      "[ok] Convers_106.wav -> Convers_106_diarization.csv | segs=91 | speakers=2\n",
      "[ok] Convers_107.wav -> Convers_107_diarization.csv | segs=72 | speakers=2\n",
      "[ok] Inten_107.wav -> Inten_107_diarization.csv | segs=82 | speakers=2\n",
      "[ok] Spon_107.wav -> Spon_107_diarization.csv | segs=97 | speakers=2\n",
      "[ok] Convers_109.wav -> Convers_109_diarization.csv | segs=67 | speakers=2\n",
      "[ok] inten_109.wav -> inten_109_diarization.csv | segs=70 | speakers=2\n",
      "[ok] Spon_109.wav -> Spon_109_diarization.csv | segs=77 | speakers=2\n",
      "[ok] Convers_11.wav -> Convers_11_diarization.csv | segs=60 | speakers=2\n",
      "[ok] Spon_11.wav -> Spon_11_diarization.csv | segs=76 | speakers=2\n",
      "[ok] Convers_110.wav -> Convers_110_diarization.csv | segs=25 | speakers=2\n",
      "[ok] Inten_110.wav -> Inten_110_diarization.csv | segs=87 | speakers=2\n",
      "[ok] Spon_110.wav -> Spon_110_diarization.csv | segs=80 | speakers=2\n",
      "[ok] Convers_111.wav -> Convers_111_diarization.csv | segs=74 | speakers=2\n",
      "[ok] Inten_111.wav -> Inten_111_diarization.csv | segs=113 | speakers=2\n",
      "[ok] Spon_111.wav -> Spon_111_diarization.csv | segs=9 | speakers=2\n",
      "[ok] 112_conversation.wav -> 112_conversation_diarization.csv | segs=38 | speakers=2\n",
      "[ok] 112_freeplay.wav -> 112_freeplay_diarization.csv | segs=100 | speakers=2\n",
      "[ok] Convers_113.wav -> Convers_113_diarization.csv | segs=56 | speakers=2\n",
      "[ok] Inten_113.wav -> Inten_113_diarization.csv | segs=71 | speakers=2\n",
      "[ok] SponPlay_113.wav -> SponPlay_113_diarization.csv | segs=75 | speakers=2\n",
      "[ok] Convers_114.wav -> Convers_114_diarization.csv | segs=76 | speakers=2\n",
      "[ok] Inten_114.wav -> Inten_114_diarization.csv | segs=92 | speakers=2\n",
      "[ok] Spon_114.wav -> Spon_114_diarization.csv | segs=73 | speakers=2\n",
      "[ok] Conver_115.wav -> Conver_115_diarization.csv | segs=33 | speakers=2\n",
      "[ok] Inten_115.wav -> Inten_115_diarization.csv | segs=31 | speakers=2\n",
      "[ok] Spon_115.wav -> Spon_115_diarization.csv | segs=35 | speakers=2\n",
      "[ok] Convers_116.wav -> Convers_116_diarization.csv | segs=101 | speakers=2\n",
      "[ok] Inten_116.wav -> Inten_116_diarization.csv | segs=109 | speakers=2\n",
      "[ok] Spon_116.wav -> Spon_116_diarization.csv | segs=81 | speakers=2\n",
      "[ok] Convers_117.wav -> Convers_117_diarization.csv | segs=162 | speakers=2\n",
      "[ok] Inten_117.wav -> Inten_117_diarization.csv | segs=317 | speakers=2\n",
      "[ok] Spon_117.wav -> Spon_117_diarization.csv | segs=319 | speakers=2\n",
      "[ok] Convers_120.wav -> Convers_120_diarization.csv | segs=36 | speakers=2\n",
      "[ok] Inten_120.wav -> Inten_120_diarization.csv | segs=44 | speakers=2\n",
      "[ok] Spon_120.wav -> Spon_120_diarization.csv | segs=76 | speakers=2\n",
      "[ok] Convers_121.wav -> Convers_121_diarization.csv | segs=80 | speakers=2\n",
      "[ok] Inten_121.wav -> Inten_121_diarization.csv | segs=91 | speakers=2\n",
      "[ok] Spon_121.wav -> Spon_121_diarization.csv | segs=129 | speakers=2\n",
      "[ok] Convers_122.wav -> Convers_122_diarization.csv | segs=35 | speakers=2\n",
      "[ok] Inten_122.wav -> Inten_122_diarization.csv | segs=41 | speakers=2\n",
      "[ok] Spon_122.wav -> Spon_122_diarization.csv | segs=37 | speakers=2\n",
      "[ok] Convers_123.wav -> Convers_123_diarization.csv | segs=74 | speakers=2\n",
      "[ok] Inten_123.wav -> Inten_123_diarization.csv | segs=89 | speakers=2\n",
      "[ok] Spon_123.wav -> Spon_123_diarization.csv | segs=199 | speakers=2\n",
      "[ok] Convers_124.wav -> Convers_124_diarization.csv | segs=155 | speakers=2\n",
      "[ok] Inten_124.wav -> Inten_124_diarization.csv | segs=322 | speakers=2\n",
      "[ok] Spon_124.wav -> Spon_124_diarization.csv | segs=321 | speakers=2\n",
      "[ok] Convers_125.wav -> Convers_125_diarization.csv | segs=52 | speakers=2\n",
      "[ok] Inten_125.wav -> Inten_125_diarization.csv | segs=49 | speakers=2\n",
      "[ok] Spon_125.wav -> Spon_125_diarization.csv | segs=41 | speakers=2\n",
      "[ok] Conver_126.wav -> Conver_126_diarization.csv | segs=35 | speakers=2\n",
      "[ok] Inten_126.wav -> Inten_126_diarization.csv | segs=45 | speakers=2\n",
      "[ok] Spon_126.wav -> Spon_126_diarization.csv | segs=44 | speakers=2\n",
      "[ok] Convers_127.wav -> Convers_127_diarization.csv | segs=110 | speakers=2\n",
      "[ok] Inten_127.wav -> Inten_127_diarization.csv | segs=116 | speakers=2\n",
      "[ok] SponPartOne_127.wav -> SponPartOne_127_diarization.csv | segs=59 | speakers=2\n",
      "[ok] SponPartThree_127.wav -> SponPartThree_127_diarization.csv | segs=88 | speakers=2\n",
      "[ok] SponPartTwo_127.wav -> SponPartTwo_127_diarization.csv | segs=60 | speakers=2\n",
      "[ok] convers_128.wav -> convers_128_diarization.csv | segs=104 | speakers=2\n",
      "[ok] Inten_128.wav -> Inten_128_diarization.csv | segs=108 | speakers=2\n",
      "[ok] Spon_128.wav -> Spon_128_diarization.csv | segs=90 | speakers=2\n",
      "[ok] 13_conversation.wav -> 13_conversation_diarization.csv | segs=111 | speakers=2\n",
      "[ok] 13_intenplay.wav -> 13_intenplay_diarization.csv | segs=24 | speakers=2\n",
      "[ok] 13_sponplay.wav -> 13_sponplay_diarization.csv | segs=45 | speakers=2\n",
      "[ok] 200_convers.wav -> 200_convers_diarization.csv | segs=111 | speakers=2\n",
      "[ok] 200_inten.wav -> 200_inten_diarization.csv | segs=86 | speakers=2\n",
      "[ok] 200_spon.wav -> 200_spon_diarization.csv | segs=96 | speakers=2\n",
      "[ok] 201_convers.wav -> 201_convers_diarization.csv | segs=8 | speakers=2\n",
      "[ok] 201_inten.wav -> 201_inten_diarization.csv | segs=51 | speakers=2\n",
      "[ok] 201_spon.wav -> 201_spon_diarization.csv | segs=37 | speakers=2\n",
      "[ok] 203.wav -> 203_diarization.csv | segs=5 | speakers=2\n",
      "[ok] 205_conver.wav -> 205_conver_diarization.csv | segs=44 | speakers=2\n",
      "[ok] 205_intent.wav -> 205_intent_diarization.csv | segs=41 | speakers=2\n",
      "[ok] 205_spon.wav -> 205_spon_diarization.csv | segs=65 | speakers=2\n",
      "[ok] 206_conver.wav -> 206_conver_diarization.csv | segs=35 | speakers=2\n",
      "[ok] 206_inten.wav -> 206_inten_diarization.csv | segs=36 | speakers=2\n",
      "[ok] 206_spon.wav -> 206_spon_diarization.csv | segs=25 | speakers=2\n",
      "[ok] 209_conv.wav -> 209_conv_diarization.csv | segs=68 | speakers=2\n",
      "[ok] 209_intentional.wav -> 209_intentional_diarization.csv | segs=92 | speakers=2\n",
      "[ok] 209_spon.wav -> 209_spon_diarization.csv | segs=100 | speakers=2\n",
      "[ok] 210_convers.wav -> 210_convers_diarization.csv | segs=46 | speakers=2\n",
      "[ok] 210_inten.wav -> 210_inten_diarization.csv | segs=96 | speakers=2\n",
      "[ok] 210_spon.wav -> 210_spon_diarization.csv | segs=147 | speakers=2\n",
      "[ok] 211_covers.wav -> 211_covers_diarization.csv | segs=66 | speakers=2\n",
      "[ok] 211_inten.wav -> 211_inten_diarization.csv | segs=62 | speakers=2\n",
      "[ok] 211_spon.wav -> 211_spon_diarization.csv | segs=34 | speakers=2\n",
      "[ok] 212_conver.wav -> 212_conver_diarization.csv | segs=33 | speakers=2\n",
      "[ok] 212_inten.wav -> 212_inten_diarization.csv | segs=75 | speakers=2\n",
      "[ok] 212_spon.wav -> 212_spon_diarization.csv | segs=75 | speakers=2\n",
      "[ok] 213_conver.wav -> 213_conver_diarization.csv | segs=73 | speakers=2\n",
      "[ok] 213_inten.wav -> 213_inten_diarization.csv | segs=83 | speakers=2\n",
      "[ok] 213_spon.wav -> 213_spon_diarization.csv | segs=96 | speakers=2\n",
      "[ok] 214_convers.wav -> 214_convers_diarization.csv | segs=80 | speakers=2\n",
      "[ok] 214_inten.wav -> 214_inten_diarization.csv | segs=80 | speakers=2\n",
      "[ok] 214_spon.wav -> 214_spon_diarization.csv | segs=78 | speakers=2\n",
      "[ok] 215_convers.wav -> 215_convers_diarization.csv | segs=110 | speakers=2\n",
      "[ok] 215_inten.wav -> 215_inten_diarization.csv | segs=110 | speakers=2\n",
      "[ok] 215_spon.wav -> 215_spon_diarization.csv | segs=139 | speakers=2\n",
      "[ok] 217_conver.wav -> 217_conver_diarization.csv | segs=93 | speakers=2\n",
      "[ok] 217_inten.wav -> 217_inten_diarization.csv | segs=102 | speakers=2\n",
      "[ok] 217_spon.wav -> 217_spon_diarization.csv | segs=220 | speakers=2\n",
      "[ok] 218_convers.wav -> 218_convers_diarization.csv | segs=64 | speakers=2\n",
      "[ok] 218_inten.wav -> 218_inten_diarization.csv | segs=226 | speakers=2\n",
      "[ok] 218_spon.wav -> 218_spon_diarization.csv | segs=102 | speakers=2\n",
      "[ok] 219_convers.wav -> 219_convers_diarization.csv | segs=60 | speakers=2\n",
      "[ok] 219_inten.wav -> 219_inten_diarization.csv | segs=117 | speakers=2\n",
      "[ok] spon_219.wav -> spon_219_diarization.csv | segs=74 | speakers=2\n",
      "[ok] 220_convers.wav -> 220_convers_diarization.csv | segs=92 | speakers=2\n",
      "[ok] 220_spon.wav -> 220_spon_diarization.csv | segs=113 | speakers=2\n",
      "[ok] 221_conv.wav -> 221_conv_diarization.csv | segs=76 | speakers=2\n",
      "[ok] 221_inten.wav -> 221_inten_diarization.csv | segs=99 | speakers=2\n",
      "[ok] 221_spon.wav -> 221_spon_diarization.csv | segs=122 | speakers=2\n",
      "[ok] 222_convers.wav -> 222_convers_diarization.csv | segs=45 | speakers=2\n",
      "[ok] 222_inten.wav -> 222_inten_diarization.csv | segs=90 | speakers=2\n",
      "[ok] 222_spon.wav -> 222_spon_diarization.csv | segs=64 | speakers=2\n",
      "[ok] 224_convers.wav -> 224_convers_diarization.csv | segs=94 | speakers=2\n",
      "[ok] 224_inten.wav -> 224_inten_diarization.csv | segs=91 | speakers=2\n",
      "[ok] 224_spon.wav -> 224_spon_diarization.csv | segs=118 | speakers=2\n",
      "[ok] 225_conver.wav -> 225_conver_diarization.csv | segs=93 | speakers=2\n",
      "[ok] 225_inten.wav -> 225_inten_diarization.csv | segs=39 | speakers=2\n",
      "[ok] 225_spon.wav -> 225_spon_diarization.csv | segs=29 | speakers=2\n",
      "[ok] 228_convers.wav -> 228_convers_diarization.csv | segs=45 | speakers=2\n",
      "[ok] 228_intetn.wav -> 228_intetn_diarization.csv | segs=69 | speakers=2\n",
      "[ok] 228_spon.wav -> 228_spon_diarization.csv | segs=77 | speakers=2\n",
      "[ok] 230_convers.wav -> 230_convers_diarization.csv | segs=30 | speakers=2\n",
      "[ok] 230_inten.wav -> 230_inten_diarization.csv | segs=25 | speakers=2\n",
      "[ok] 230_spon.wav -> 230_spon_diarization.csv | segs=19 | speakers=2\n",
      "[ok] 231_convers.wav -> 231_convers_diarization.csv | segs=93 | speakers=2\n",
      "[ok] 231_inten.wav -> 231_inten_diarization.csv | segs=69 | speakers=2\n",
      "[ok] 231_spon.wav -> 231_spon_diarization.csv | segs=151 | speakers=2\n",
      "[ok] 232_convers.wav -> 232_convers_diarization.csv | segs=125 | speakers=2\n",
      "[ok] 232_inten.wav -> 232_inten_diarization.csv | segs=103 | speakers=2\n",
      "[ok] 232_sponOne.wav -> 232_sponOne_diarization.csv | segs=19 | speakers=2\n",
      "[ok] 232_sponTwo.wav -> 232_sponTwo_diarization.csv | segs=75 | speakers=2\n",
      "[ok] 234_conv.wav -> 234_conv_diarization.csv | segs=63 | speakers=2\n",
      "[ok] 234_inten.wav -> 234_inten_diarization.csv | segs=102 | speakers=2\n",
      "[ok] 234_spon.wav -> 234_spon_diarization.csv | segs=100 | speakers=2\n",
      "[ok] 237_conv.wav -> 237_conv_diarization.csv | segs=72 | speakers=2\n",
      "[ok] 237_inten.wav -> 237_inten_diarization.csv | segs=91 | speakers=2\n",
      "[ok] 237_spon.wav -> 237_spon_diarization.csv | segs=140 | speakers=2\n",
      "[ok] 238_Conv.wav -> 238_Conv_diarization.csv | segs=52 | speakers=2\n",
      "[ok] 238_Inten.wav -> 238_Inten_diarization.csv | segs=49 | speakers=2\n",
      "[ok] 238_spon.wav -> 238_spon_diarization.csv | segs=90 | speakers=2\n",
      "[ok] 239_convers.wav -> 239_convers_diarization.csv | segs=53 | speakers=2\n",
      "[ok] 239_intent.wav -> 239_intent_diarization.csv | segs=86 | speakers=2\n",
      "[ok] 239_spon.wav -> 239_spon_diarization.csv | segs=134 | speakers=2\n",
      "[ok] 24_convers.wav -> 24_convers_diarization.csv | segs=35 | speakers=2\n",
      "[ok] 240_convers.wav -> 240_convers_diarization.csv | segs=58 | speakers=2\n",
      "[ok] 240_inten.wav -> 240_inten_diarization.csv | segs=77 | speakers=2\n",
      "[ok] 240_spon.wav -> 240_spon_diarization.csv | segs=49 | speakers=2\n",
      "[ok] 241_convers.wav -> 241_convers_diarization.csv | segs=59 | speakers=2\n",
      "[ok] 241_inten.wav -> 241_inten_diarization.csv | segs=53 | speakers=2\n",
      "[ok] 241_spon.wav -> 241_spon_diarization.csv | segs=63 | speakers=2\n",
      "[ok] 242_convers.wav -> 242_convers_diarization.csv | segs=53 | speakers=2\n",
      "[ok] 242_inten.wav -> 242_inten_diarization.csv | segs=103 | speakers=2\n",
      "[ok] 242_spon.wav -> 242_spon_diarization.csv | segs=97 | speakers=2\n",
      "[ok] 244_convers.wav -> 244_convers_diarization.csv | segs=134 | speakers=2\n",
      "[ok] 244_inten.wav -> 244_inten_diarization.csv | segs=89 | speakers=2\n",
      "[ok] 244_spon.wav -> 244_spon_diarization.csv | segs=177 | speakers=2\n",
      "[ok] 245_convers.wav -> 245_convers_diarization.csv | segs=39 | speakers=2\n",
      "[ok] 245_inten.wav -> 245_inten_diarization.csv | segs=49 | speakers=2\n",
      "[ok] 245_sponOne.wav -> 245_sponOne_diarization.csv | segs=22 | speakers=2\n",
      "[ok] 245_sponTwo.wav -> 245_sponTwo_diarization.csv | segs=45 | speakers=2\n",
      "[ok] 248_Conv.wav -> 248_Conv_diarization.csv | segs=66 | speakers=2\n",
      "[ok] 248_Inten.wav -> 248_Inten_diarization.csv | segs=60 | speakers=2\n",
      "[ok] 248_spon.wav -> 248_spon_diarization.csv | segs=127 | speakers=2\n",
      "[ok] 250_convers.wav -> 250_convers_diarization.csv | segs=43 | speakers=2\n",
      "[ok] 250_inten.wav -> 250_inten_diarization.csv | segs=56 | speakers=2\n",
      "[ok] 250_spon.wav -> 250_spon_diarization.csv | segs=65 | speakers=2\n",
      "[ok] 251_convers.wav -> 251_convers_diarization.csv | segs=72 | speakers=2\n",
      "[ok] 251_inten.wav -> 251_inten_diarization.csv | segs=79 | speakers=2\n",
      "[ok] 251_Spon.wav -> 251_Spon_diarization.csv | segs=85 | speakers=2\n",
      "[ok] 252_conv.wav -> 252_conv_diarization.csv | segs=53 | speakers=2\n",
      "[ok] 252_inten.wav -> 252_inten_diarization.csv | segs=68 | speakers=2\n",
      "[ok] 252_spon.wav -> 252_spon_diarization.csv | segs=88 | speakers=2\n",
      "[ok] 253_convers.wav -> 253_convers_diarization.csv | segs=173 | speakers=2\n",
      "[ok] 253_inten.wav -> 253_inten_diarization.csv | segs=124 | speakers=2\n",
      "[ok] 253_spon.wav -> 253_spon_diarization.csv | segs=164 | speakers=2\n",
      "[ok] 255_convers.wav -> 255_convers_diarization.csv | segs=172 | speakers=2\n",
      "[ok] 255_inten.wav -> 255_inten_diarization.csv | segs=52 | speakers=2\n",
      "[ok] 255_spon.wav -> 255_spon_diarization.csv | segs=124 | speakers=2\n",
      "[ok] 258_conv.wav -> 258_conv_diarization.csv | segs=63 | speakers=2\n",
      "[ok] 258_inten.wav -> 258_inten_diarization.csv | segs=98 | speakers=2\n",
      "[ok] 258_spon.wav -> 258_spon_diarization.csv | segs=82 | speakers=2\n",
      "[ok] 260_convers.wav -> 260_convers_diarization.csv | segs=51 | speakers=2\n",
      "[ok] 260_inten.wav -> 260_inten_diarization.csv | segs=75 | speakers=2\n",
      "[ok] 260_spon.wav -> 260_spon_diarization.csv | segs=105 | speakers=2\n",
      "[ok] 27_convers.wav -> 27_convers_diarization.csv | segs=69 | speakers=2\n",
      "[ok] 27_inten.wav -> 27_inten_diarization.csv | segs=62 | speakers=2\n",
      "[ok] 27_spon.wav -> 27_spon_diarization.csv | segs=61 | speakers=2\n",
      "[ok] 29_convers.wav -> 29_convers_diarization.csv | segs=112 | speakers=2\n",
      "[ok] 29_inten.wav -> 29_inten_diarization.csv | segs=99 | speakers=2\n",
      "[ok] 29_spon.wav -> 29_spon_diarization.csv | segs=32 | speakers=2\n",
      "[ok] Spon_3.wav -> Spon_3_diarization.csv | segs=30 | speakers=2\n",
      "[ok] 30_convers.wav -> 30_convers_diarization.csv | segs=38 | speakers=2\n",
      "[ok] 30_spon.wav -> 30_spon_diarization.csv | segs=88 | speakers=2\n",
      "[ok] 5_intenplay.wav -> 5_intenplay_diarization.csv | segs=81 | speakers=2\n",
      "[ok] 5_spontplay.wav -> 5_spontplay_diarization.csv | segs=89 | speakers=2\n",
      "[ok] Convers_6.wav -> Convers_6_diarization.csv | segs=41 | speakers=2\n",
      "[ok] intent_6.wav -> intent_6_diarization.csv | segs=33 | speakers=2\n",
      "[ok] spon_6.wav -> spon_6_diarization.csv | segs=50 | speakers=2\n",
      "[ok] Conves_7.wav -> Conves_7_diarization.csv | segs=23 | speakers=2\n",
      "\n",
      "Done. Found 217 WAV(s), processed 217, output dir: O:\\\\MyThesis\\\\DataSets\\\\Michal\\\\outputsResults\n"
     ]
    }
   ],
   "source": [
    "import os, math, csv, traceback\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import librosa, soundfile as sf\n",
    "import torch\n",
    "from speechbrain.pretrained import SpeakerRecognition\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# ======================= Config =======================\n",
    "INPUT_DIR  = r\"O:\\\\MyThesis\\\\DataSets\\\\Michal\\\\Audio\\\\\"     # where wav files will be saved\n",
    "OUTPUT_DIR = r\"O:\\\\MyThesis\\\\DataSets\\\\Michal\\\\outputsResults\" # where CSVs will be written\n",
    "RECURSIVE = True                                           # search subfolders\n",
    "SKIP_IF_EXISTS = True                                      # skip files with an existing CSV\n",
    "FORCE_NUM_SPEAKERS = 2                                     # set to int (e.g., 2) or None to auto-estimate (2..5)\n",
    "\n",
    "# VAD & windowing\n",
    "VAD_TOP_DB = 25            # lower  more sensitive VAD (2035 sensible range)\n",
    "MIN_SPEECH_SEC = 0.30      # drop micro-blips\n",
    "WIN_SEC = 1.5              # embedding window length (s)\n",
    "HOP_SEC = 0.75             # hop (s)  50% overlap\n",
    "MERGE_GAP_SEC = 0.20       # merge adjacent same-speaker segments if gap < this\n",
    "# ======================================================\n",
    "\n",
    "def fmt_time_ss_msec(t: float) -> str:\n",
    "    t = max(0.0, float(t))\n",
    "    s = int(t)\n",
    "    ms = int(round((t - s) * 1000))\n",
    "    if ms == 1000:\n",
    "        s += 1; ms = 0\n",
    "    return f\"{s}.{ms:03d}\"\n",
    "\n",
    "def get_speech_segments(y, sr, top_db=25, min_len=0.3, frame_length=2048, hop_length=512):\n",
    "    \"\"\"Return non-silent (start_s, end_s) intervals via librosa.effects.split.\"\"\"\n",
    "    intervals = librosa.effects.split(y, top_db=top_db, frame_length=frame_length, hop_length=hop_length)\n",
    "    segs = []\n",
    "    for a, b in intervals:\n",
    "        s, e = a / sr, b / sr\n",
    "        if e - s >= min_len:\n",
    "            segs.append((s, e))\n",
    "    return segs\n",
    "\n",
    "def sliding_windows(seg_start, seg_end, win, hop):\n",
    "    t = seg_start\n",
    "    out = []\n",
    "    while t < seg_end:\n",
    "        tend = min(t + win, seg_end)\n",
    "        if tend - t >= 0.5:  # need at least 0.5s for stable embedding\n",
    "            out.append((t, tend))\n",
    "        t += hop\n",
    "    return out\n",
    "\n",
    "def merge_same_label(segments, gap=0.2):\n",
    "    \"\"\"segments: list of (start, end, label), sorted by time; merge contiguous/nearby same labels.\"\"\"\n",
    "    if not segments:\n",
    "        return []\n",
    "    merged = []\n",
    "    cur_s, cur_e, cur_l = segments[0]\n",
    "    for s, e, l in segments[1:]:\n",
    "        if l == cur_l and 0 <= s - cur_e <= gap:\n",
    "            cur_e = max(cur_e, e)\n",
    "        else:\n",
    "            merged.append((cur_s, cur_e, cur_l))\n",
    "            cur_s, cur_e, cur_l = s, e, l\n",
    "    merged.append((cur_s, cur_e, cur_l))\n",
    "    return merged\n",
    "\n",
    "def pick_top_two_by_talktime(segments):\n",
    "    totals = {}\n",
    "    for s, e, l in segments:\n",
    "        totals[l] = totals.get(l, 0.0) + (e - s)\n",
    "    items = sorted(totals.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    top = [lab for lab, _ in items[:2]]\n",
    "    while len(top) < 2:\n",
    "        top.append(f\"UNK{len(top)+1}\")\n",
    "    return top[0], top[1]\n",
    "\n",
    "def diarize_one_file(audio_path: Path, out_csv_path: Path, recog: SpeakerRecognition):\n",
    "    # Load audio mono 16 kHz\n",
    "    y, sr = librosa.load(str(audio_path), sr=16000, mono=True)\n",
    "    # VAD\n",
    "    speech_regions = get_speech_segments(y, sr, top_db=VAD_TOP_DB, min_len=MIN_SPEECH_SEC)\n",
    "    # Prepare output dir\n",
    "    out_csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # If no speech, write header only\n",
    "    if not speech_regions:\n",
    "        with open(out_csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            csv.writer(f).writerow([\"Begin Time - ss.msec\",\"End Time - ss.msec\",\"Duration - ss.msec\",\"speaker1\",\"speaker2\",\"other\"])\n",
    "        return {\"segments\": 0, \"speakers\": 0}\n",
    "\n",
    "    # Windows for embeddings\n",
    "    windows = []\n",
    "    for s, e in speech_regions:\n",
    "        windows.extend(sliding_windows(s, e, WIN_SEC, HOP_SEC))\n",
    "    if not windows:\n",
    "        with open(out_csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            csv.writer(f).writerow([\"Begin Time - ss.msec\",\"End Time - ss.msec\",\"Duration - ss.msec\",\"speaker1\",\"speaker2\",\"other\"])\n",
    "        return {\"segments\": 0, \"speakers\": 0}\n",
    "\n",
    "    # Embeddings\n",
    "    embs = []\n",
    "    for s, e in windows:\n",
    "        chunk = y[int(s*sr):int(e*sr)]\n",
    "        wav = torch.tensor(chunk, dtype=torch.float32).unsqueeze(0)  # [1, T]\n",
    "        with torch.no_grad():\n",
    "            emb = recog.encode_batch(wav)  # [1, D]\n",
    "        embs.append(emb.squeeze().cpu().numpy().reshape(-1))\n",
    "    X = np.vstack(embs)  # [N, D]\n",
    "\n",
    "    # Number of speakers\n",
    "    if FORCE_NUM_SPEAKERS and FORCE_NUM_SPEAKERS >= 1:\n",
    "        k = int(FORCE_NUM_SPEAKERS)\n",
    "    else:\n",
    "        best_k, best_score = 2, -1.0\n",
    "        for cand in range(2, 6):\n",
    "            labels_c = AgglomerativeClustering(n_clusters=cand, linkage=\"ward\").fit_predict(X)\n",
    "            if 1 < len(set(labels_c)) < len(labels_c):\n",
    "                score = silhouette_score(X, labels_c)\n",
    "                if score > best_score:\n",
    "                    best_score, best_k = score, cand\n",
    "        k = best_k\n",
    "    clustering = AgglomerativeClustering(n_clusters=k, linkage=\"ward\")\n",
    "    win_labels = clustering.fit_predict(X)\n",
    "\n",
    "    # Windows -> merged segments\n",
    "    labeled_windows = sorted([(windows[i][0], windows[i][1], int(win_labels[i])) for i in range(len(windows))],\n",
    "                             key=lambda x: (x[0], x[1]))\n",
    "    merged = merge_same_label(labeled_windows, gap=MERGE_GAP_SEC)\n",
    "\n",
    "    # Map to speaker1/2/other\n",
    "    spk1, spk2 = pick_top_two_by_talktime(merged)\n",
    "\n",
    "    # Write CSV\n",
    "    with open(out_csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"Begin Time - ss.msec\",\"End Time - ss.msec\",\"Duration - ss.msec\",\"Mother\",\"Child\",\"Others\"])\n",
    "        for s, e, lab in merged:\n",
    "            w.writerow([\n",
    "                fmt_time_ss_msec(s),\n",
    "                fmt_time_ss_msec(e),\n",
    "                fmt_time_ss_msec(e - s),\n",
    "                1 if lab == spk1 else 0,\n",
    "                1 if lab == spk2 else 0,\n",
    "                1 if lab not in (spk1, spk2) else 0\n",
    "            ])\n",
    "    return {\"segments\": len(merged), \"speakers\": k}\n",
    "\n",
    "def main():\n",
    "    in_dir = Path(INPUT_DIR)\n",
    "    out_dir = Path(OUTPUT_DIR)\n",
    "    pattern = \"**/*.wav\" if RECURSIVE else \"*.wav\"\n",
    "    files = sorted(in_dir.glob(pattern))\n",
    "    if not files:\n",
    "        print(f\"No WAVs found in: {INPUT_DIR}\")\n",
    "        return\n",
    "\n",
    "    # Load model once\n",
    "    recog = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\")\n",
    "\n",
    "    total_files = 0\n",
    "    processed = 0\n",
    "    for wav_path in files:\n",
    "        total_files += 1\n",
    "        out_name = wav_path.stem + \"_diarization.csv\"\n",
    "        out_csv_path = out_dir / out_name\n",
    "        if SKIP_IF_EXISTS and out_csv_path.exists():\n",
    "            print(f\"[skip] {wav_path.name} -> {out_csv_path.name} (exists)\")\n",
    "            continue\n",
    "        try:\n",
    "            stats = diarize_one_file(wav_path, out_csv_path, recog)\n",
    "            print(f\"[ok] {wav_path.name} -> {out_csv_path.name} | segs={stats['segments']} | speakers={stats['speakers']}\")\n",
    "            processed += 1\n",
    "        except Exception as e:\n",
    "            print(f\"[error] {wav_path} :: {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "    print(f\"\\nDone. Found {total_files} WAV(s), processed {processed}, output dir: {OUTPUT_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding CIBs (From CIBs CSV File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 213 segment CSV files.\n",
      "\n",
      "DONE\n",
      "Processed: 213\n",
      "Skipped (no Sub in filename): 0\n",
      "Skipped (Sub not found in subjects table): 0\n",
      "Skipped (read/parse errors): 0\n",
      "Output folder: O:\\MyThesis\\DataSets\\Michal\\outputsResultsWithCIBs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG (edit these)\n",
    "# -----------------------------\n",
    "SUBJECTS_CSV = r\"O:\\\\MyThesis\\\\DataSets\\\\Michal\\\\CIB_code\\\\Michal_Subjects.csv\"         # (1)\n",
    "SEGMENTS_FOLDER = r\"O:\\\\MyThesis\\\\DataSets\\\\Michal\\\\outputsResults\"    # (2)\n",
    "OUTPUT_FOLDER = r\"O:\\\\MyThesis\\\\DataSets\\\\Michal\\\\outputsResultsWithCIBs\" # output\n",
    "# -----------------------------\n",
    "\n",
    "SUBJECT_COLS_EXPECTED = [\n",
    "    \"Sub\", \"AqScore\",\n",
    "    \"SENSIT\", \"INTRUS\", \"LIMITS\", \"INVOLVE\",\n",
    "    \"WITHDRAW\", \"COMPLY\", \"SYNCH\", \"DYADNEG\"\n",
    "]\n",
    "\n",
    "SEGMENT_COLS_EXPECTED = [\n",
    "    \"Begin Time - ss.msec\",\n",
    "    \"End Time - ss.msec\",\n",
    "    \"Duration - ss.msec\",\n",
    "    \"Mother\",\n",
    "    \"Child\"\n",
    "    # \"Others\" intentionally excluded\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def extract_sub_from_filename(filename: str):\n",
    "    \"\"\"\n",
    "    Tries to extract Sub as an integer from the filename.\n",
    "    Works for common patterns like:\n",
    "      - 'Sub12.csv'\n",
    "      - 'subject_12_segments.csv'\n",
    "      - '12_anything.csv'\n",
    "    Returns int or None if not found.\n",
    "    \"\"\"\n",
    "    m = re.search(r\"(?:sub|subject)\\s*[_-]?\\s*(\\d+)\", filename, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "\n",
    "    m = re.search(r\"(\\d+)\", filename)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    subjects_path = Path(SUBJECTS_CSV)\n",
    "    seg_folder = Path(SEGMENTS_FOLDER)\n",
    "    out_folder = Path(OUTPUT_FOLDER)\n",
    "    out_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Load subjects table (1)\n",
    "    # -----------------------------\n",
    "    subj_df = pd.read_csv(subjects_path)\n",
    "\n",
    "    missing = [c for c in SUBJECT_COLS_EXPECTED if c not in subj_df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            \"Subjects CSV is missing required columns:\\n\"\n",
    "            + \", \".join(missing)\n",
    "            + f\"\\nFound columns: {list(subj_df.columns)}\"\n",
    "        )\n",
    "\n",
    "    subj_df[\"Sub\"] = pd.to_numeric(subj_df[\"Sub\"], errors=\"raise\").astype(int)\n",
    "    subj_lookup = subj_df.set_index(\"Sub\")[SUBJECT_COLS_EXPECTED[1:]].to_dict(orient=\"index\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Process segment CSVs (2)\n",
    "    # -----------------------------\n",
    "    segment_files = sorted(seg_folder.glob(\"*.csv\"))\n",
    "    if not segment_files:\n",
    "        print(f\"No CSV files found in: {seg_folder}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(segment_files)} segment CSV files.\")\n",
    "\n",
    "    not_found_sub = []     # list of dicts: filename, extracted_sub\n",
    "    no_sub_in_name = []    # list of filenames\n",
    "    read_errors = []       # list of dicts: filename, error\n",
    "    processed = 0\n",
    "\n",
    "    for fpath in segment_files:\n",
    "        sub_id = extract_sub_from_filename(fpath.name)\n",
    "        if sub_id is None:\n",
    "            no_sub_in_name.append(fpath.name)\n",
    "            continue\n",
    "\n",
    "        if sub_id not in subj_lookup:\n",
    "            not_found_sub.append({\"filename\": fpath.name, \"extracted_sub\": sub_id})\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            seg_df = pd.read_csv(fpath)\n",
    "        except Exception as e:\n",
    "            read_errors.append({\"filename\": fpath.name, \"error\": str(e)})\n",
    "            continue\n",
    "\n",
    "        missing_seg_cols = [c for c in SEGMENT_COLS_EXPECTED if c not in seg_df.columns]\n",
    "        if missing_seg_cols:\n",
    "            print(f\"WARNING: {fpath.name} missing columns: {missing_seg_cols}\")\n",
    "\n",
    "        # Add subject columns to every row\n",
    "        meta = subj_lookup[sub_id]\n",
    "        seg_df.insert(0, \"Sub\", sub_id)\n",
    "        for col, val in meta.items():\n",
    "            seg_df[col] = val\n",
    "\n",
    "        # -----------------------------\n",
    "        # EXCLUDE \"Others\" COLUMN\n",
    "        # -----------------------------\n",
    "        if \"Others\" in seg_df.columns:\n",
    "            seg_df = seg_df.drop(columns=[\"Others\"])\n",
    "\n",
    "        # Save\n",
    "        out_path = out_folder / fpath.name\n",
    "        seg_df.to_csv(out_path, index=False)\n",
    "        processed += 1\n",
    "\n",
    "    # -----------------------------\n",
    "    # Summary + show skipped filenames\n",
    "    # -----------------------------\n",
    "    print(\"\\nDONE\")\n",
    "    print(f\"Processed: {processed}\")\n",
    "    print(f\"Skipped (no Sub in filename): {len(no_sub_in_name)}\")\n",
    "    print(f\"Skipped (Sub not found in subjects table): {len(not_found_sub)}\")\n",
    "    print(f\"Skipped (read/parse errors): {len(read_errors)}\")\n",
    "    print(f\"Output folder: {out_folder}\")\n",
    "\n",
    "    if no_sub_in_name:\n",
    "        print(\"\\n--- Skipped: NO Sub number detected in filename ---\")\n",
    "        for fname in no_sub_in_name:\n",
    "            print(\"  -\", fname)\n",
    "\n",
    "    if not_found_sub:\n",
    "        print(\"\\n--- Skipped: Sub NOT FOUND in subjects table ---\")\n",
    "        for item in not_found_sub:\n",
    "            print(f\"  - {item['filename']}  (extracted Sub={item['extracted_sub']})\")\n",
    "\n",
    "    if read_errors:\n",
    "        print(\"\\n--- Skipped: CSV read/parse errors ---\")\n",
    "        for item in read_errors:\n",
    "            print(f\"  - {item['filename']}  (error={item['error']})\")\n",
    "\n",
    "    # # -----------------------------\n",
    "    # # Save skipped report CSV\n",
    "    # # -----------------------------\n",
    "    # skipped_rows = []\n",
    "\n",
    "    # for fname in no_sub_in_name:\n",
    "    #     skipped_rows.append({\"filename\": fname, \"reason\": \"no_sub_in_filename\", \"extracted_sub\": None, \"error\": None})\n",
    "\n",
    "    # for item in not_found_sub:\n",
    "    #     skipped_rows.append({\"filename\": item[\"filename\"], \"reason\": \"sub_not_in_subjects_table\",\n",
    "    #                          \"extracted_sub\": item[\"extracted_sub\"], \"error\": None})\n",
    "\n",
    "    # for item in read_errors:\n",
    "    #     skipped_rows.append({\"filename\": item[\"filename\"], \"reason\": \"csv_read_error\",\n",
    "    #                          \"extracted_sub\": extract_sub_from_filename(item[\"filename\"]), \"error\": item[\"error\"]})\n",
    "\n",
    "    # if skipped_rows:\n",
    "    #     report_path = out_folder / \"skipped_report.csv\"\n",
    "    #     pd.DataFrame(skipped_rows).to_csv(report_path, index=False)\n",
    "    #     print(f\"\\nSaved skipped report: {report_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Direct / Stand Alone Features (Vocal and interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAIRS FOUND: 213\n",
      "UNMATCHED WAVS: 0\n",
      "PAIR: Convers_100.wav <-> Convers_100_diarization.csv\n",
      "PAIR: Inten_100.wav <-> Inten_100_diarization.csv\n",
      "PAIR: Spon_100.wav <-> Spon_100_diarization.csv\n",
      "PAIR: Convers_101.wav <-> Convers_101_diarization.csv\n",
      "PAIR: Inten_101.wav <-> Inten_101_diarization.csv\n",
      "PAIR: Spon_101.wav <-> Spon_101_diarization.csv\n",
      "PAIR: Convers_102.wav <-> Convers_102_diarization.csv\n",
      "PAIR: Inten_102.wav <-> Inten_102_diarization.csv\n",
      "PAIR: Spon_102.wav <-> Spon_102_diarization.csv\n",
      "PAIR: Convers_103.wav <-> Convers_103_diarization.csv\n",
      "PAIR: Inten_103.wav <-> Inten_103_diarization.csv\n",
      "PAIR: Spon_103.wav <-> Spon_103_diarization.csv\n",
      "PAIR: Convers_104.wav <-> Convers_104_diarization.csv\n",
      "PAIR: Inten_104.wav <-> Inten_104_diarization.csv\n",
      "PAIR: Spon_104.wav <-> Spon_104_diarization.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pairs: 100%|| 213/213 [3:53:37<00:00, 65.81s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FULL PIPELINE: deterministic WAV<->CSV pairing\n",
    "# WAV:  Convers_100.wav\n",
    "# CSV:  Convers_100_diarization.csv\n",
    "# Output: Convers_100_features.csv\n",
    "# ============================================================\n",
    "\n",
    "# ----------------------------\n",
    "# NO WARNINGS (must be first)\n",
    "# ----------------------------\n",
    "import os, warnings\n",
    "os.environ[\"NUMBA_DISABLE_JIT\"] = \"1\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ----------------------------\n",
    "# Imports\n",
    "# ----------------------------\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----------------------------\n",
    "# Columns that already exist in each diarization CSV\n",
    "# ----------------------------\n",
    "LABEL_COLS = [\n",
    "    \"Sub\",\"AqScore\", \"SENSIT\", \"INTRUS\", \"LIMITS\",\n",
    "    \"INVOLVE\", \"WITHDRAW\", \"COMPLY\", \"SYNCH\", \"DYADNEG\"\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# Speaker helper\n",
    "# ============================================================\n",
    "def detect_speaker(row):\n",
    "    m = int(row.get(\"Mother\", 0)) if not pd.isna(row.get(\"Mother\", 0)) else 0\n",
    "    c = int(row.get(\"Child\", 0)) if not pd.isna(row.get(\"Child\", 0)) else 0\n",
    "    if m == 1 and c == 0:\n",
    "        return \"Mother\"\n",
    "    if c == 1 and m == 0:\n",
    "        return \"Child\"\n",
    "    if m == 1 and c == 1:\n",
    "        return \"Both\"\n",
    "    return \"None\"\n",
    "\n",
    "# ============================================================\n",
    "# CSV loader with AUTO sec/ms + label extraction\n",
    "# ============================================================\n",
    "def load_segments_csv(csv_path: str, audio_duration_sec: float):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    # ignore Others if present\n",
    "    if \"Others\" in df.columns:\n",
    "        df = df.drop(columns=[\"Others\"])\n",
    "\n",
    "    required = [\"Begin Time - ss.msec\", \"End Time - ss.msec\", \"Duration - ss.msec\", \"Mother\", \"Child\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns in {csv_path}: {missing}\")\n",
    "\n",
    "    # Extract label values once (assumed constant per file)\n",
    "    labels = {c: (df[c].iloc[0] if c in df.columns and len(df) else np.nan) for c in LABEL_COLS}\n",
    "\n",
    "    begin_raw = df[\"Begin Time - ss.msec\"].astype(float)\n",
    "    end_raw   = df[\"End Time - ss.msec\"].astype(float)\n",
    "    dur_raw   = df[\"Duration - ss.msec\"].astype(float)\n",
    "\n",
    "    # auto-detect milliseconds vs seconds\n",
    "    is_ms = end_raw.max() > audio_duration_sec * 3.0\n",
    "    if is_ms:\n",
    "        begin_raw /= 1000.0\n",
    "        end_raw   /= 1000.0\n",
    "        dur_raw   /= 1000.0\n",
    "\n",
    "    df[\"segment_begin_sec\"] = begin_raw\n",
    "    df[\"segment_end_sec\"]   = end_raw\n",
    "    df[\"duration\"]          = dur_raw\n",
    "    df[\"speaker\"] = df.apply(detect_speaker, axis=1)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[\"segment_index\"] = np.arange(len(df), dtype=int)\n",
    "\n",
    "    return df, labels\n",
    "\n",
    "# ============================================================\n",
    "# Pitch (robust)\n",
    "# ============================================================\n",
    "def compute_pitch(y_seg, sr):\n",
    "    if y_seg.size < int(0.06 * sr):\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    rms = librosa.feature.rms(y=y_seg)[0]\n",
    "    if np.mean(rms) < 1e-4:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    try:\n",
    "        f0, _, _ = librosa.pyin(\n",
    "            y_seg, sr=sr,\n",
    "            fmin=50, fmax=3000,\n",
    "            frame_length=1024, hop_length=256\n",
    "        )\n",
    "        if f0 is None:\n",
    "            return np.nan, np.nan\n",
    "        f0v = f0[~np.isnan(f0)]\n",
    "        if f0v.size < 3:\n",
    "            return np.nan, np.nan\n",
    "        return float(np.mean(f0v)), float(np.std(f0v))\n",
    "    except Exception:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "# ============================================================\n",
    "# Extract audio features for a segment (returns NaNs if empty)\n",
    "# ============================================================\n",
    "def extract_features(y_seg, sr, n_mfcc=20):\n",
    "    if y_seg is None or len(y_seg) == 0:\n",
    "        feats = {\n",
    "            \"spectral_centroid\": np.nan,\n",
    "            \"spectral_bandwidth\": np.nan,\n",
    "            \"spectral_rolloff\": np.nan,\n",
    "            \"zcr\": np.nan,\n",
    "            \"rms\": np.nan,\n",
    "            \"pitch_level\": np.nan,\n",
    "            \"pitch_std\": np.nan,\n",
    "            \"intensity_std\": np.nan,\n",
    "            \"tonal_centroid\": np.nan,\n",
    "            \"mel_spec\": np.nan,\n",
    "            \"log_mel_spec\": np.nan,\n",
    "            \"chroma\": np.nan,\n",
    "        }\n",
    "        for i in range(1, n_mfcc + 1):\n",
    "            feats[f\"mfcc_{i}\"] = np.nan\n",
    "        return feats\n",
    "\n",
    "    sc  = librosa.feature.spectral_centroid(y=y_seg, sr=sr)\n",
    "    sb  = librosa.feature.spectral_bandwidth(y=y_seg, sr=sr)\n",
    "    sro = librosa.feature.spectral_rolloff(y=y_seg, sr=sr, roll_percent=0.85)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y_seg)\n",
    "    rms = librosa.feature.rms(y=y_seg)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=y_seg, sr=sr, n_mfcc=n_mfcc)\n",
    "\n",
    "    pitch_level, pitch_std = compute_pitch(y_seg, sr)\n",
    "\n",
    "    mel = librosa.feature.melspectrogram(y=y_seg, sr=sr, n_mels=64)\n",
    "    log_mel = librosa.power_to_db(mel, ref=np.max) if mel.size else np.array([])\n",
    "\n",
    "    chroma = librosa.feature.chroma_stft(y=y_seg, sr=sr)\n",
    "\n",
    "    try:\n",
    "        y_h = librosa.effects.harmonic(y_seg)\n",
    "        tonnetz = librosa.feature.tonnetz(y=y_h, sr=sr)\n",
    "        tonal_centroid = float(np.mean(tonnetz)) if tonnetz.size else np.nan\n",
    "    except Exception:\n",
    "        tonal_centroid = np.nan\n",
    "\n",
    "    feats = {\n",
    "        \"spectral_centroid\": float(np.mean(sc)) if sc.size else np.nan,\n",
    "        \"spectral_bandwidth\": float(np.mean(sb)) if sb.size else np.nan,\n",
    "        \"spectral_rolloff\": float(np.mean(sro)) if sro.size else np.nan,\n",
    "        \"zcr\": float(np.mean(zcr)) if zcr.size else np.nan,\n",
    "        \"rms\": float(np.mean(rms)) if rms.size else np.nan,\n",
    "        \"intensity_std\": float(np.std(rms)) if rms.size else np.nan,\n",
    "        \"pitch_level\": pitch_level,\n",
    "        \"pitch_std\": pitch_std,\n",
    "        \"tonal_centroid\": tonal_centroid,\n",
    "        \"mel_spec\": float(np.mean(mel)) if mel.size else np.nan,\n",
    "        \"log_mel_spec\": float(np.mean(log_mel)) if log_mel.size else np.nan,\n",
    "        \"chroma\": float(np.mean(chroma)) if chroma.size else np.nan,\n",
    "    }\n",
    "\n",
    "    for i in range(1, n_mfcc + 1):\n",
    "        feats[f\"mfcc_{i}\"] = float(np.mean(mfcc[i - 1])) if mfcc.size else np.nan\n",
    "\n",
    "    return feats\n",
    "\n",
    "# ============================================================\n",
    "# Deterministic pairing: wav_stem -> wav_stem + \"_diarization.csv\"\n",
    "# ============================================================\n",
    "def build_pairs_diarization(wav_root, csv_dir):\n",
    "    wavs = sorted(glob.glob(os.path.join(wav_root, \"**\", \"*.wav\"), recursive=True))\n",
    "    csvs = sorted(glob.glob(os.path.join(csv_dir, \"*.csv\")))\n",
    "\n",
    "    csv_by_stem = {Path(c).stem: c for c in csvs}\n",
    "\n",
    "    pairs = []\n",
    "    unmatched = []\n",
    "    for w in wavs:\n",
    "        wav_stem = Path(w).stem\n",
    "        expected_csv_stem = f\"{wav_stem}_diarization\"\n",
    "        c = csv_by_stem.get(expected_csv_stem)\n",
    "        if c is None:\n",
    "            unmatched.append(w)\n",
    "        else:\n",
    "            pairs.append((w, c))\n",
    "    return pairs, unmatched\n",
    "\n",
    "# ============================================================\n",
    "# Process one pair: output rows == input rows\n",
    "# ============================================================\n",
    "def process_pair(wav_path, csv_path, out_csv_path, target_sr=16000):\n",
    "    y, sr = librosa.load(wav_path, sr=target_sr, mono=False)\n",
    "\n",
    "    # force mono\n",
    "    if isinstance(y, np.ndarray) and y.ndim == 2:\n",
    "        y = np.mean(y, axis=0)\n",
    "\n",
    "    audio_duration_sec = len(y) / sr\n",
    "    seg_df, labels = load_segments_csv(csv_path, audio_duration_sec)\n",
    "\n",
    "    rows = []\n",
    "    audio_len = len(y)\n",
    "\n",
    "    for i, r in seg_df.iterrows():\n",
    "        b = float(r[\"segment_begin_sec\"])\n",
    "        e = float(r[\"segment_end_sec\"])\n",
    "\n",
    "        # Clamp and use floor/ceil to avoid empty due to rounding\n",
    "        start = int(np.floor(b * sr))\n",
    "        end   = int(np.ceil(e * sr))\n",
    "        start = max(0, min(start, audio_len))\n",
    "        end   = max(0, min(end, audio_len))\n",
    "\n",
    "        y_seg = y[start:end] if end > start else np.array([], dtype=np.float32)\n",
    "\n",
    "        feats = extract_features(y_seg, sr, n_mfcc=20)\n",
    "\n",
    "        # next speaker flags\n",
    "        speaker_now = r[\"speaker\"]\n",
    "        speaker_next = seg_df.loc[i + 1, \"speaker\"] if i + 1 < len(seg_df) else \"None\"\n",
    "        mother_to_child = int(speaker_now == \"Mother\" and speaker_next == \"Child\")\n",
    "        child_to_mother = int(speaker_now == \"Child\" and speaker_next == \"Mother\")\n",
    "\n",
    "        row = {}\n",
    "        row.update(labels)\n",
    "        row.update(feats)\n",
    "        row.update({\n",
    "            \"speaker\": speaker_now,\n",
    "            \"segment_index\": int(r[\"segment_index\"]),\n",
    "            \"segment_begin_sec\": b,\n",
    "            \"segment_end_sec\": e,\n",
    "            \"duration\": float(r[\"duration\"]),\n",
    "            \"mother_to_child\": mother_to_child,\n",
    "            \"child_to_mother\": child_to_mother,\n",
    "            \"mother_pitch\": feats[\"pitch_level\"] if speaker_now == \"Mother\" else np.nan,\n",
    "            \"child_pitch\": feats[\"pitch_level\"] if speaker_now == \"Child\" else np.nan,\n",
    "        })\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    out_df = pd.DataFrame(rows)\n",
    "\n",
    "    ordered = (\n",
    "        LABEL_COLS\n",
    "        + [\"spectral_centroid\", \"spectral_bandwidth\", \"spectral_rolloff\", \"zcr\", \"rms\"]\n",
    "        + [f\"mfcc_{i}\" for i in range(1, 21)]\n",
    "        + [\"pitch_level\", \"pitch_std\", \"intensity_std\", \"duration\",\n",
    "           \"tonal_centroid\", \"mel_spec\", \"log_mel_spec\", \"chroma\",\n",
    "           \"speaker\", \"segment_index\", \"segment_begin_sec\", \"segment_end_sec\",\n",
    "           \"mother_to_child\", \"child_to_mother\", \"mother_pitch\", \"child_pitch\"]\n",
    "    )\n",
    "    ordered = [c for c in ordered if c in out_df.columns]\n",
    "    out_df = out_df[ordered]\n",
    "\n",
    "    os.makedirs(Path(out_csv_path).parent, exist_ok=True)\n",
    "    out_df.to_csv(out_csv_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage:\n",
    "    #   python extract_vocal_interaction_features.py\n",
    "    #\n",
    "    # Edit these paths (Windows example)\n",
    "    WAV_ROOT = r\"O:\\\\MyThesis\\\\DataSets\\\\Michal\\\\Audio\"     # folder that contains subfolders of wav files\n",
    "    SEGMENTS_CSV_DIR = r\"O:\\\\MyThesis\\\\DataSets\\\\Michal\\\\outputsResultsWithCIBs\"\n",
    "    OUTPUT_FOLDER = r\"O:\\\\MyThesis\\\\DataSets\\\\Michal\\\\outputsResultsWithStandAloneFeatures\"\n",
    "\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    pairs, unmatched = build_pairs_diarization(WAV_ROOT, SEGMENTS_CSV_DIR)\n",
    "\n",
    "    print(f\"PAIRS FOUND: {len(pairs)}\")\n",
    "    print(f\"UNMATCHED WAVS: {len(unmatched)}\")\n",
    "\n",
    "    for w, c in pairs[:15]:\n",
    "        print(\"PAIR:\", Path(w).name, \"<->\", Path(c).name)\n",
    "\n",
    "    for wav_path, csv_path in tqdm(pairs, desc=\"Processing pairs\"):\n",
    "        out_csv = os.path.join(OUTPUT_DIR, f\"{Path(wav_path).stem}_features.csv\")\n",
    "        process_pair(wav_path, csv_path, out_csv)\n",
    "\n",
    "    print(\"DONE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add CIBs Prediction and save folder with all csv file that each file include all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote 213 files to: O:\\\\MyThesis\\\\DataSets\\\\Michal\\\\outputsResultsWithAllFeatures\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG: features + targets (as you provided)\n",
    "# ============================================================\n",
    "INPUT_FEATURES = [\n",
    "    \"spectral_centroid\", \"spectral_bandwidth\", \"spectral_rolloff\",\n",
    "    \"zcr\", \"rms\",\n",
    "    *[f\"mfcc_{i}\" for i in range(1, 21)],\n",
    "    \"pitch_level\", \"pitch_std\", \"intensity_std\", \"duration\",\n",
    "    \"tonal_centroid\",\n",
    "    \"mel_spec\", \"log_mel_spec\", \"chroma\",\n",
    "    \"mother_to_child\", \"child_to_mother\",\n",
    "    \"mother_pitch\", \"child_pitch\"\n",
    "]\n",
    "\n",
    "TARGETS = [\n",
    "    \"SENSIT\", \"INTRUS\", \"LIMITS\",\n",
    "    \"INVOLVE\", \"WITHDRAW\", \"COMPLY\",\n",
    "    \"SYNCH\", \"DYADNEG\"\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# Helper utils\n",
    "# ============================================================\n",
    "def ensure_dir(folder: str):\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def safe_numeric_df(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in cols:\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "    return out\n",
    "\n",
    "def fit_predict_one_target(\n",
    "    train_df: pd.DataFrame,\n",
    "    pred_df: pd.DataFrame,\n",
    "    feature_cols: list[str],\n",
    "    target_col: str,\n",
    "    n_splits: int = 5,\n",
    "    random_state: int = 42,\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Train model on train_df for target_col, then predict on pred_df.\n",
    "    Returns:\n",
    "      - oof_pred (cross-validated predictions for train_df rows)\n",
    "      - test_pred (predictions for pred_df rows)\n",
    "    \"\"\"\n",
    "    # Keep only rows with non-null target in training\n",
    "    train_use = train_df.dropna(subset=[target_col]).copy()\n",
    "    if train_use.empty:\n",
    "        raise ValueError(f\"No labeled rows found for target '{target_col}' (all NaN).\")\n",
    "\n",
    "    X_train = train_use[feature_cols].values\n",
    "    y_train = train_use[target_col].values\n",
    "    X_pred = pred_df[feature_cols].values\n",
    "\n",
    "    # A solid default regressor; tune if you want later\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=600,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        reg_lambda=1.0,\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"xgb\", model),\n",
    "    ])\n",
    "\n",
    "    # If too few samples, reduce splits\n",
    "    k = min(n_splits, len(train_use))\n",
    "    if k < 2:\n",
    "        # Fit once (no CV possible)\n",
    "        pipe.fit(X_train, y_train)\n",
    "        oof = pipe.predict(X_train)\n",
    "        test_pred = pipe.predict(X_pred)\n",
    "        return oof, test_pred\n",
    "\n",
    "    cv = KFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # OOF predictions for sanity checks / debugging\n",
    "    oof = cross_val_predict(pipe, X_train, y_train, cv=cv, n_jobs=-1)\n",
    "\n",
    "    # Fit on full labeled set and predict on pred_df\n",
    "    pipe.fit(X_train, y_train)\n",
    "    test_pred = pipe.predict(X_pred)\n",
    "    return oof, test_pred\n",
    "\n",
    "# ============================================================\n",
    "# Main pipeline: folder -> folder\n",
    "# ============================================================\n",
    "def predict_targets_for_csv_folder(\n",
    "    input_folder: str,\n",
    "    output_folder: str,\n",
    "    feature_cols: list[str] = INPUT_FEATURES,\n",
    "    targets: list[str] = TARGETS,\n",
    "    file_pattern: str = \"*.csv\",\n",
    "    n_splits: int = 5,\n",
    "    random_state: int = 42,\n",
    "    output_suffix: str = \"_PRED\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads ALL CSVs in input_folder, trains per-target XGBRegressor using rows\n",
    "    where target exists, predicts missing targets (and also writes predicted columns)\n",
    "    for every file, and saves to output_folder.\n",
    "\n",
    "    Output:\n",
    "      - Same CSV structure + added columns: <TARGET>_pred\n",
    "      - Also fills missing original TARGET values with predictions (optional behavior below)\n",
    "    \"\"\"\n",
    "    ensure_dir(output_folder)\n",
    "\n",
    "    paths = sorted(glob.glob(os.path.join(input_folder, file_pattern)))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No CSV files found in: {input_folder}\")\n",
    "\n",
    "    # Load all, keep origin path for saving back\n",
    "    dfs = []\n",
    "    for p in paths:\n",
    "        df = pd.read_csv(p)\n",
    "        df[\"__source_file__\"] = os.path.basename(p)\n",
    "        dfs.append(df)\n",
    "\n",
    "    all_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Validate required feature columns\n",
    "    missing_feats = [c for c in feature_cols if c not in all_df.columns]\n",
    "    if missing_feats:\n",
    "        raise ValueError(\n",
    "            \"Missing required INPUT_FEATURES columns:\\n\"\n",
    "            + \"\\n\".join(missing_feats)\n",
    "        )\n",
    "\n",
    "    # Make numeric where relevant\n",
    "    all_df = safe_numeric_df(all_df, feature_cols + targets)\n",
    "\n",
    "    # If features have NaNs, XGBoost can handle some NaNs, but scaler can't.\n",
    "    # So: fill feature NaNs with 0 (or you can use median impute).\n",
    "    all_df[feature_cols] = all_df[feature_cols].fillna(0)\n",
    "\n",
    "    # Create prediction columns\n",
    "    for t in targets:\n",
    "        all_df[f\"{t}_pred\"] = np.nan\n",
    "\n",
    "    # Train/predict per target (global model across all files)\n",
    "    for t in targets:\n",
    "        if t not in all_df.columns:\n",
    "            # If the target column doesn't exist at all, create it as NaN\n",
    "            all_df[t] = np.nan\n",
    "\n",
    "        # Predict for all rows in all_df (same frame used as pred_df)\n",
    "        _, pred = fit_predict_one_target(\n",
    "            train_df=all_df,\n",
    "            pred_df=all_df,\n",
    "            feature_cols=feature_cols,\n",
    "            target_col=t,\n",
    "            n_splits=n_splits,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        all_df[f\"{t}_pred\"] = pred\n",
    "\n",
    "        # OPTIONAL: fill missing true labels with predictions\n",
    "        all_df[t] = all_df[t].where(~all_df[t].isna(), all_df[f\"{t}_pred\"])\n",
    "\n",
    "    # Save back per original file\n",
    "    for fname, sub_df in all_df.groupby(\"__source_file__\", sort=False):\n",
    "        out_df = sub_df.drop(columns=[\"__source_file__\"])\n",
    "\n",
    "        stem = Path(fname).stem\n",
    "        out_name = f\"{stem}{output_suffix}.csv\"\n",
    "        out_path = os.path.join(output_folder, out_name)\n",
    "        out_df.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f\"Done. Wrote {len(paths)} files to: {output_folder}\")\n",
    "\n",
    "# ============================================================\n",
    "# Example run\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    INPUT_FOLDER = r\"O:\\\\MyThesis\\\\DataSets\\\\Michal\\\\outputsResultsWithStandAloneFeatures\"\n",
    "    OUTPUT_FOLDER = r\"O:\\\\MyThesis\\\\DataSets\\\\Michal\\\\outputsResultsWithAllFeatures\"\n",
    "\n",
    "    predict_targets_for_csv_folder(\n",
    "        input_folder=INPUT_FOLDER,\n",
    "        output_folder=OUTPUT_FOLDER,\n",
    "        n_splits=5,          # CV folds for OOF; final model fits on all labeled rows\n",
    "        random_state=42,\n",
    "        output_suffix=\"_AllFeatures\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
